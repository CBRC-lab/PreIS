{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install gdown"
      ],
      "metadata": {
        "id": "0wDwIlNDyaen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from model import RITA_s\n",
        "from transformers import AutoTokenizer\n",
        "import gdown"
      ],
      "metadata": {
        "id": "Y9xSOlwwzai1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download the pretrained model: FT-SDA\n",
        "\n",
        "url = 'https://drive.google.com/uc?id=1Td2H5RwohfvvOLBvr3-vhwixt2P7W3yg'\n",
        "output = 'FT_SDA.bin'\n",
        "gdown.download(url, output, quiet=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "cf74pMAd-7jG",
        "outputId": "ae6f7e07-dd45-4015-bf56-d20d2be312a2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Td2H5RwohfvvOLBvr3-vhwixt2P7W3yg\n",
            "To: /content/FT_SDA.bin\n",
            "100%|██████████| 341M/341M [00:02<00:00, 126MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'FT_SDA.bin'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load model & tokenizer\n",
        "\n",
        "device = torch.device(\"cuda\")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"lightonai/RITA_s\")\n",
        "tokenizer.add_special_tokens({'pad_token': '<PAD>'})\n",
        "\n",
        "model = RITA_s()\n",
        "model.to(device)\n",
        "model.load_state_dict(torch.load(\"FT_SDA.bin\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJ7JszHJyf72",
        "outputId": "74de6f0a-bfd4-47ad-cd2c-a1329ab3f55a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sample sequence (true label = 3)\n",
        "sequence = \"MKTIIALSYVFCLAFGQDLPGSDNSTATLCLGHHAVPNGTIVKTITDDQIEVTNATELVQSSSTGKICNNPHRVLDGRDCTLIDALLGDPHCDVFQDETWDLFVERSNAFSNCYPYDVPDYASLRSLVASSGTLEFITEGFTWAGVTQNGGSNACKRGPASGFFSRLNWLTKSGSAYPVLNVTMPNNDNFDKLYIWGVHHPSTNQEQTNLYVQASGRVTVSTRRSQQTIIPNIGSRPWVRGQSGRISIHWTIVKPGDVLVINSNGNLIAPRGYFKMRTGKSSIMRSDAPIDTCISECITPNGSIPNDKPFQNVNKITYGACPKYVKQDTLKLATGMRNVPEKQTRGLFGAIAGFIENGWEGMIDGWYGFRHQNSEGTGQAADLKSTQAAIDQINGKLNRVIEKTNEKFHQIEKEFSEVEGRIQDLEKYVEDTKIDLWSYNAELLVALENQHTIDLTDSEMNKLFEKTRRQLRENAEDMGNGCFKIYHKCDNACIESIRNGTYDHDIYRDEALNNRFQIKGVELKSGYKDWILWISFAISCFLLCVVLLGFIMWACQRGNIRCNICI\""
      ],
      "metadata": {
        "id": "O7D3p_yE1FSg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get inputs\n",
        "\n",
        "inputs = tokenizer.encode_plus(\n",
        "    sequence,\n",
        "    None,\n",
        "    add_special_tokens = True,\n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "ids = inputs[\"input_ids\"].to(device)\n",
        "mask = inputs[\"attention_mask\"].to(device)\n",
        "token_type_ids = inputs[\"token_type_ids\"].to(device)"
      ],
      "metadata": {
        "id": "6yMo72ti06Fj"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make predictions\n",
        "\n",
        "model = model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "\n",
        "    outputs = model(\n",
        "        input_ids = ids,\n",
        "        attention_mask = mask,\n",
        "        token_type_ids = token_type_ids\n",
        "    )\n",
        "\n",
        "_, preds = torch.max(outputs, dim=1)\n",
        "print(preds.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d41DJQoY1OC6",
        "outputId": "7b6712a0-cef3-434f-c758-c82b067c2e2e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n"
          ]
        }
      ]
    }
  ]
}